{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DnokyRPqBJ7n"
   },
   "source": [
    "# CIS 419/519 Homework 1\n",
    "\n",
    "Name: Yongxin Guo\n",
    "\n",
    "Pennkey: yoguo\n",
    "\n",
    "PennID: 68201122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JXCMO-KSHept"
   },
   "outputs": [],
   "source": [
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "random.seed(42)  # don't change this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Asyzto_DKfBQ"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-c1ca36f9ad02>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-c1ca36f9ad02>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    baseDir = ## TODO: insert path to data file\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Load all data tables\n",
    "baseDir = ## TODO: insert path to data file\n",
    "df = pd.read_csv(baseDir+'NHANES-diabetes-hw-train.csv')\n",
    "\n",
    "# Output debugging info\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UvNtFvGqKfDx"
   },
   "outputs": [],
   "source": [
    "# Print information about the dataset\n",
    "print('Percentage of instances with missing features:')\n",
    "print(df.isnull().sum(axis=0)/df.shape[0])\n",
    "print()\n",
    "print('Class information:')\n",
    "print(df['DIABETIC'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QH3IMkmxm3E2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vhfk9CQoXfae"
   },
   "source": [
    "## **Preprocessing**\n",
    "\n",
    "The first key step in any data modeling task is cleaning your dataset. Explore your dataset and figure out what sort of preprocessing is required. Good preprocessing can make or break your final model. So choose wisely.\n",
    "\n",
    "Some of the preprocessing steps that you can consider are :\n",
    "\n",
    "\n",
    "*   One-hot encoding of variables\n",
    "*   Missing value imputation\n",
    "*   Removing outliers\n",
    "*   Converting binary features into 0-1 representation\n",
    "\n",
    "\n",
    "Feel free to reuse code you've already written in HW 0.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Fupod-VnNzu"
   },
   "outputs": [],
   "source": [
    "# TODO Insert your preprocessing code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F_HqomJOap0j"
   },
   "source": [
    "## **Modeling**\n",
    "\n",
    "In this section, you are tasked with building a Decision Tree classifier to predict whether or not a patient has diabetes. The overall goal of this exercise is to investigate the dataset and develop features that would improve your model performance.\n",
    "\n",
    "To help with this process, we have provided the structure for two helper functions. These functions will help in tuning your model as well as validating your model's performance.\n",
    "\n",
    "Complete these two functions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rsr6KV5wKfJB"
   },
   "outputs": [],
   "source": [
    "def cross_validated_accuracy(DecisionTreeClassifier, X, y, num_trials, num_folds, random_seed):\n",
    "  random.seed(random_seed)\n",
    "  \"\"\"\n",
    "   Args:\n",
    "        DecisionTreeClassifier: An Sklearn DecisionTreeClassifier (e.g., created by \"tree.DecisionTreeClassifier(criterion='entropy')\")\n",
    "        X: Input features\n",
    "        y: Labels\n",
    "        num_trials: Number of trials to run of cross validation\n",
    "        num_folds: Number of folds (the \"k\" in \"k-folds\")\n",
    "        random_seed: Seed for uniform execution (Do not change this) \n",
    "\n",
    "    Returns:\n",
    "        cvScore: The mean accuracy of the cross-validation experiment\n",
    "\n",
    "    Notes:\n",
    "        1. You may NOT use the cross-validation functions provided by Sklearn\n",
    "  \"\"\"\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "  ## TODO ##\n",
    "\n",
    "\n",
    "  return cvScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XNISvwuvKvjP"
   },
   "outputs": [],
   "source": [
    "def automatic_dt_pruning(DecisionTreeClassifier, X, y, num_trials, num_folds, random_seed):\n",
    "  random.seed(random_seed)\n",
    "  \"\"\"\n",
    "  Returns the pruning parameter (i.e., ccp_alpha) with the highest cross-validated accuracy\n",
    "\n",
    "  Args:\n",
    "        DecisionTreeClassifier  : An Sklearn DecisionTreeClassifier (e.g., created by \"tree.DecisionTreeClassifier(criterion='entropy')\")      \n",
    "        X (Pandas.DataFrame)    : Input Features\n",
    "        y (Pandas.Series)       : Labels\n",
    "        num_trials              : Number of trials to run of cross validation\n",
    "        num_folds               : Number of folds for cross validation (The \"k\" in \"k-folds\") \n",
    "        random_seed             : Seed for uniform execution (Do not change this)\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        ccp_alpha : Tuned pruning paramter with highest cross-validated accuracy\n",
    "\n",
    "    Notes:\n",
    "        1. Don't change any other Decision Tree Classifier parameters other than ccp_alpha\n",
    "        2. Use the cross_validated_accuracy function you implemented to find the cross-validated accuracy\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "  ## TODO ##\n",
    "\n",
    "\n",
    "  return ccp_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-LfgMo78b6SQ"
   },
   "source": [
    "## **Tuning and Testing**\n",
    "\n",
    "With the helper functions and your processed dataset, build a Decision Tree classifier to classify Diabetic patients and tune it to maximize model performance.\n",
    "\n",
    "Once you are done with your modeling process, test your model on the test dataset and output your predictions in a file titled \"cis519_hw1_predictions.csv\", with one row per prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSVrMo_RcYti"
   },
   "outputs": [],
   "source": [
    "## TODO ##"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW1_Skeleton.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
