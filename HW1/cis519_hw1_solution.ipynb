{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DnokyRPqBJ7n"
   },
   "source": [
    "# CIS 419/519 Homework 1\n",
    "\n",
    "Name: Yongxin Guo\n",
    "\n",
    "Pennkey: yongxin\n",
    "\n",
    "PennID: 68201122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JXCMO-KSHept"
   },
   "outputs": [],
   "source": [
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "random.seed(42)  # don't change this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Asyzto_DKfBQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8140, 1812)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>RIDSTATR</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>RIDAGEYR</th>\n",
       "      <th>RIDAGEMN</th>\n",
       "      <th>RIDRETH1</th>\n",
       "      <th>RIDRETH3</th>\n",
       "      <th>RIDEXMON</th>\n",
       "      <th>RIDEXAGM</th>\n",
       "      <th>...</th>\n",
       "      <th>WHD080L</th>\n",
       "      <th>WHD110</th>\n",
       "      <th>WHD120</th>\n",
       "      <th>WHD130</th>\n",
       "      <th>WHD140</th>\n",
       "      <th>WHQ150</th>\n",
       "      <th>WHQ030M</th>\n",
       "      <th>WHQ500</th>\n",
       "      <th>WHQ520</th>\n",
       "      <th>DIABETIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76195</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76958</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80248</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80213</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76753</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1812 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SEQN  SDDSRVYR  RIDSTATR  RIAGENDR  RIDAGEYR  RIDAGEMN  RIDRETH1  \\\n",
       "0  76195         8         2         1        18       NaN         5   \n",
       "1  76958         8         2         2        57       NaN         2   \n",
       "2  80248         8         2         2        29       NaN         2   \n",
       "3  80213         8         2         2         0       5.0         1   \n",
       "4  76753         8         2         1        61       NaN         3   \n",
       "\n",
       "   RIDRETH3  RIDEXMON  RIDEXAGM  ...  WHD080L  WHD110  WHD120  WHD130  WHD140  \\\n",
       "0         7       1.0     217.0  ...      NaN     NaN     NaN     NaN   138.0   \n",
       "1         2       1.0       NaN  ...      NaN   135.0   115.0    67.0   150.0   \n",
       "2         2       2.0       NaN  ...      NaN     NaN   125.0     NaN   160.0   \n",
       "3         1       2.0       6.0  ...      NaN     NaN     NaN     NaN     NaN   \n",
       "4         3       2.0       NaN  ...      NaN   160.0   160.0    69.0   180.0   \n",
       "\n",
       "   WHQ150  WHQ030M  WHQ500  WHQ520  DIABETIC  \n",
       "0    18.0      NaN     NaN     NaN         0  \n",
       "1    45.0      NaN     NaN     NaN         0  \n",
       "2    28.0      NaN     NaN     NaN         0  \n",
       "3     NaN      NaN     NaN     NaN         0  \n",
       "4    30.0      NaN     NaN     NaN         0  \n",
       "\n",
       "[5 rows x 1812 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all data tables\n",
    "baseDir = \"\" ## TODO: insert path to data file\n",
    "df = pd.read_csv(baseDir+'hw1-NHANES-diabetes-train.csv')\n",
    "\n",
    "# Output debugging info\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UvNtFvGqKfDx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of instances with missing features:\n",
      "SEQN        0.000000\n",
      "SDDSRVYR    0.000000\n",
      "RIDSTATR    0.000000\n",
      "RIAGENDR    0.000000\n",
      "RIDAGEYR    0.000000\n",
      "RIDAGEMN    0.936241\n",
      "RIDRETH1    0.000000\n",
      "RIDRETH3    0.000000\n",
      "RIDEXMON    0.035258\n",
      "RIDEXAGM    0.587346\n",
      "DMQMILIZ    0.383415\n",
      "DMQADFC     0.948771\n",
      "DMDBORN4    0.000000\n",
      "DMDCITZN    0.000369\n",
      "DMDYRSUS    0.813391\n",
      "DMDEDUC3    0.724570\n",
      "DMDEDUC2    0.431450\n",
      "DMDMARTL    0.431450\n",
      "RIDEXPRG    0.867322\n",
      "SIALANG     0.000000\n",
      "SIAPROXY    0.000123\n",
      "SIAINTRP    0.000000\n",
      "FIALANG     0.011794\n",
      "FIAPROXY    0.011794\n",
      "FIAINTRP    0.011794\n",
      "MIALANG     0.278378\n",
      "MIAPROXY    0.278256\n",
      "MIAINTRP    0.278133\n",
      "AIALANGA    0.376044\n",
      "DMDHHSIZ    0.000000\n",
      "              ...   \n",
      "WHD080A     0.829361\n",
      "WHD080B     0.911179\n",
      "WHD080C     0.920147\n",
      "WHD080D     0.819533\n",
      "WHD080E     0.961425\n",
      "WHD080F     0.976290\n",
      "WHD080G     0.987592\n",
      "WHD080H     0.988698\n",
      "WHD080I     0.992260\n",
      "WHD080J     0.979238\n",
      "WHD080K     0.997543\n",
      "WHD080M     0.897420\n",
      "WHD080N     0.983538\n",
      "WHD080O     0.931081\n",
      "WHD080P     0.998403\n",
      "WHD080Q     0.888575\n",
      "WHD080R     0.899140\n",
      "WHD080S     0.906265\n",
      "WHD080T     0.900491\n",
      "WHD080U     0.998403\n",
      "WHD080L     0.997174\n",
      "WHD110      0.587469\n",
      "WHD120      0.504545\n",
      "WHD130      0.729484\n",
      "WHD140      0.398894\n",
      "WHQ150      0.407371\n",
      "WHQ030M     0.853563\n",
      "WHQ500      0.853563\n",
      "WHQ520      0.853563\n",
      "DIABETIC    0.000000\n",
      "Length: 1812, dtype: float64\n",
      "\n",
      "Class information:\n",
      "0    7447\n",
      "1     693\n",
      "Name: DIABETIC, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print information about the dataset\n",
    "print('Percentage of instances with missing features:')\n",
    "print(df.isnull().sum(axis=0)/df.shape[0])\n",
    "print()\n",
    "print('Class information:')\n",
    "print(df['DIABETIC'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QH3IMkmxm3E2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C\n",
       "0  1  0  0\n",
       "1  1  1  1\n",
       "2  1  0  1\n",
       "3  1  0  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C\n",
       "0  1  0  0\n",
       "1  1  1  1\n",
       "2  0  0  1\n",
       "3  0  1  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C  A  B  C\n",
       "0  1  0  0  1  0  0\n",
       "1  1  1  1  1  1  1\n",
       "2  1  0  1  0  0  1\n",
       "3  1  0  1  0  1  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test section\n",
    "# display(df.describe())\n",
    "dftest = pd.DataFrame({'A':[1,1,1,1],'B':[0,1,0,0], 'C':[0,1,1,1]})\n",
    "dftest1 = pd.DataFrame({'A':[1,1,0,0],'B':[0,1,0,1], 'C':[0,1,1,1]})\n",
    "display(dftest)\n",
    "display(dftest1)\n",
    "display(pd.concat([dftest,dftest1], axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vhfk9CQoXfae"
   },
   "source": [
    "## **Preprocessing**\n",
    "\n",
    "The first key step in any data modeling task is cleaning your dataset. Explore your dataset and figure out what sort of preprocessing is required. Good preprocessing can make or break your final model. So choose wisely.\n",
    "\n",
    "Some of the preprocessing steps that you can consider are :\n",
    "\n",
    "\n",
    "*   One-hot encoding of variables\n",
    "*   Missing value imputation\n",
    "*   Removing outliers\n",
    "*   Converting binary features into 0-1 representation\n",
    "\n",
    "\n",
    "Feel free to reuse code you've already written in HW 0.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Fupod-VnNzu"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>RIDSTATR</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>RIDAGEYR</th>\n",
       "      <th>RIDAGEMN</th>\n",
       "      <th>RIDRETH1</th>\n",
       "      <th>RIDRETH3</th>\n",
       "      <th>RIDEXMON</th>\n",
       "      <th>RIDEXAGM</th>\n",
       "      <th>...</th>\n",
       "      <th>WHD080L</th>\n",
       "      <th>WHD110</th>\n",
       "      <th>WHD120</th>\n",
       "      <th>WHD130</th>\n",
       "      <th>WHD140</th>\n",
       "      <th>WHQ150</th>\n",
       "      <th>WHQ030M</th>\n",
       "      <th>WHQ500</th>\n",
       "      <th>WHQ520</th>\n",
       "      <th>DIABETIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8140.000000</td>\n",
       "      <td>8140.0</td>\n",
       "      <td>8140.000000</td>\n",
       "      <td>8140.000000</td>\n",
       "      <td>8140.000000</td>\n",
       "      <td>519.000000</td>\n",
       "      <td>8140.000000</td>\n",
       "      <td>8140.000000</td>\n",
       "      <td>7853.000000</td>\n",
       "      <td>3359.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3358.000000</td>\n",
       "      <td>4033.000000</td>\n",
       "      <td>2202.000000</td>\n",
       "      <td>4893.000000</td>\n",
       "      <td>4824.000000</td>\n",
       "      <td>1192.000000</td>\n",
       "      <td>1192.000000</td>\n",
       "      <td>1192.000000</td>\n",
       "      <td>8140.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>78643.620270</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.964742</td>\n",
       "      <td>1.514742</td>\n",
       "      <td>31.540295</td>\n",
       "      <td>10.325626</td>\n",
       "      <td>3.093120</td>\n",
       "      <td>3.293243</td>\n",
       "      <td>1.512543</td>\n",
       "      <td>108.020244</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>412.695354</td>\n",
       "      <td>565.303992</td>\n",
       "      <td>371.082652</td>\n",
       "      <td>320.504394</td>\n",
       "      <td>516.604892</td>\n",
       "      <td>2.588087</td>\n",
       "      <td>2.303691</td>\n",
       "      <td>1.758389</td>\n",
       "      <td>0.085135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2944.779954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184443</td>\n",
       "      <td>0.499813</td>\n",
       "      <td>24.354202</td>\n",
       "      <td>6.831390</td>\n",
       "      <td>1.264086</td>\n",
       "      <td>1.617535</td>\n",
       "      <td>0.499874</td>\n",
       "      <td>69.606070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1509.896278</td>\n",
       "      <td>1969.887519</td>\n",
       "      <td>1708.659654</td>\n",
       "      <td>1099.580444</td>\n",
       "      <td>6886.374513</td>\n",
       "      <td>0.790769</td>\n",
       "      <td>1.225281</td>\n",
       "      <td>0.713558</td>\n",
       "      <td>0.279100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>73557.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>76088.750000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>78643.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>81201.250000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>83731.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 1781 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               SEQN  SDDSRVYR     RIDSTATR     RIAGENDR     RIDAGEYR  \\\n",
       "count   8140.000000    8140.0  8140.000000  8140.000000  8140.000000   \n",
       "mean   78643.620270       8.0     1.964742     1.514742    31.540295   \n",
       "std     2944.779954       0.0     0.184443     0.499813    24.354202   \n",
       "min    73557.000000       8.0     1.000000     1.000000     0.000000   \n",
       "25%    76088.750000       8.0     2.000000     1.000000    10.000000   \n",
       "50%    78643.000000       8.0     2.000000     2.000000    26.000000   \n",
       "75%    81201.250000       8.0     2.000000     2.000000    52.000000   \n",
       "max    83731.000000       8.0     2.000000     2.000000    80.000000   \n",
       "\n",
       "         RIDAGEMN     RIDRETH1     RIDRETH3     RIDEXMON     RIDEXAGM  ...  \\\n",
       "count  519.000000  8140.000000  8140.000000  7853.000000  3359.000000  ...   \n",
       "mean    10.325626     3.093120     3.293243     1.512543   108.020244  ...   \n",
       "std      6.831390     1.264086     1.617535     0.499874    69.606070  ...   \n",
       "min      0.000000     1.000000     1.000000     1.000000     0.000000  ...   \n",
       "25%      5.000000     2.000000     2.000000     1.000000    46.000000  ...   \n",
       "50%      9.000000     3.000000     3.000000     2.000000   104.000000  ...   \n",
       "75%     16.000000     4.000000     4.000000     2.000000   167.000000  ...   \n",
       "max     24.000000     5.000000     7.000000     2.000000   239.000000  ...   \n",
       "\n",
       "       WHD080L       WHD110       WHD120       WHD130       WHD140  \\\n",
       "count     23.0  3358.000000  4033.000000  2202.000000  4893.000000   \n",
       "mean      40.0   412.695354   565.303992   371.082652   320.504394   \n",
       "std        0.0  1509.896278  1969.887519  1708.659654  1099.580444   \n",
       "min       40.0    75.000000    55.000000    50.000000    85.000000   \n",
       "25%       40.0   140.000000   125.000000    63.000000   155.000000   \n",
       "50%       40.0   165.000000   148.000000    66.000000   185.000000   \n",
       "75%       40.0   198.000000   179.000000    70.000000   225.000000   \n",
       "max       40.0  9999.000000  9999.000000  9999.000000  9999.000000   \n",
       "\n",
       "             WHQ150      WHQ030M       WHQ500       WHQ520     DIABETIC  \n",
       "count   4824.000000  1192.000000  1192.000000  1192.000000  8140.000000  \n",
       "mean     516.604892     2.588087     2.303691     1.758389     0.085135  \n",
       "std     6886.374513     0.790769     1.225281     0.713558     0.279100  \n",
       "min       10.000000     1.000000     1.000000     1.000000     0.000000  \n",
       "25%       25.000000     3.000000     1.000000     1.000000     0.000000  \n",
       "50%       38.000000     3.000000     2.000000     2.000000     0.000000  \n",
       "75%       53.000000     3.000000     3.000000     2.000000     0.000000  \n",
       "max    99999.000000     9.000000     9.000000     9.000000     1.000000  \n",
       "\n",
       "[8 rows x 1781 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  31  non-numerical features needed to be replaced with OHE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Here is the onehot version of data below: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>RIDSTATR</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>RIDAGEYR</th>\n",
       "      <th>RIDAGEMN</th>\n",
       "      <th>RIDRETH1</th>\n",
       "      <th>RIDRETH3</th>\n",
       "      <th>RIDEXMON</th>\n",
       "      <th>RIDEXAGM</th>\n",
       "      <th>...</th>\n",
       "      <th>SMD100BR__USA GOLD</th>\n",
       "      <th>SMD100BR__VIRGINIA SLIMS</th>\n",
       "      <th>SMD100BR__VIRGINIA SLIMS GOLD</th>\n",
       "      <th>SMD100BR__VIRGINIA SLIMS SUPERSLIMS</th>\n",
       "      <th>SMD100BR__VIRGINIA SLIMS SUPERSLIMS GOLD</th>\n",
       "      <th>SMD100BR__WAVE</th>\n",
       "      <th>SMD100BR__WILD HORSE RED</th>\n",
       "      <th>SMD100BR__WINSTON</th>\n",
       "      <th>SMD100BR__WINSTON GOLD</th>\n",
       "      <th>SMD100BR__WINSTON RED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76195</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76958</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80248</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80213</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76753</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2430 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SEQN  SDDSRVYR  RIDSTATR  RIAGENDR  RIDAGEYR  RIDAGEMN  RIDRETH1  \\\n",
       "0  76195         8         2         1        18       NaN         5   \n",
       "1  76958         8         2         2        57       NaN         2   \n",
       "2  80248         8         2         2        29       NaN         2   \n",
       "3  80213         8         2         2         0       5.0         1   \n",
       "4  76753         8         2         1        61       NaN         3   \n",
       "\n",
       "   RIDRETH3  RIDEXMON  RIDEXAGM  ...  SMD100BR__USA GOLD  \\\n",
       "0         7       1.0     217.0  ...                   0   \n",
       "1         2       1.0       NaN  ...                   0   \n",
       "2         2       2.0       NaN  ...                   0   \n",
       "3         1       2.0       6.0  ...                   0   \n",
       "4         3       2.0       NaN  ...                   0   \n",
       "\n",
       "   SMD100BR__VIRGINIA SLIMS  SMD100BR__VIRGINIA SLIMS GOLD  \\\n",
       "0                         0                              0   \n",
       "1                         0                              0   \n",
       "2                         0                              0   \n",
       "3                         0                              0   \n",
       "4                         0                              0   \n",
       "\n",
       "   SMD100BR__VIRGINIA SLIMS SUPERSLIMS  \\\n",
       "0                                    0   \n",
       "1                                    0   \n",
       "2                                    0   \n",
       "3                                    0   \n",
       "4                                    0   \n",
       "\n",
       "   SMD100BR__VIRGINIA SLIMS SUPERSLIMS GOLD  SMD100BR__WAVE  \\\n",
       "0                                         0               0   \n",
       "1                                         0               0   \n",
       "2                                         0               0   \n",
       "3                                         0               0   \n",
       "4                                         0               0   \n",
       "\n",
       "   SMD100BR__WILD HORSE RED  SMD100BR__WINSTON  SMD100BR__WINSTON GOLD  \\\n",
       "0                         0                  0                       0   \n",
       "1                         0                  0                       0   \n",
       "2                         0                  0                       0   \n",
       "3                         0                  0                       0   \n",
       "4                         0                  0                       0   \n",
       "\n",
       "   SMD100BR__WINSTON RED  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 2430 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO Insert your preprocessing code here\n",
    "# read the data again\n",
    "df = pd.read_csv(baseDir+'hw1-NHANES-diabetes-train.csv')\n",
    "# Display the statistics information of the data\n",
    "display(df.describe())\n",
    "#------------------------------One-hot Encoding---------------------------------------\n",
    "# Find out if there is any non-numerical features\n",
    "non_num_count = (df.dtypes == object).sum() # there is 31 non-numerical features\n",
    "print('There are ', non_num_count, ' non-numerical features needed to be replaced with OHE')\n",
    "non_num_pos = (df.dtypes == object) # a boolean series indicating which col is object\n",
    "non_num_col = df.columns[non_num_pos] # get the non-numerical feature column\n",
    "onehots_col = non_num_col + \"_\" # define the prefix\n",
    "df_onehots = pd.get_dummies(df[non_num_col], prefix = onehots_col) # get the onehots col\n",
    "df.drop(non_num_col, axis = 1, inplace = True) # drop the non-numerical col\n",
    "df = pd.concat([df, df_onehots], axis = 1) # concatenate the onehots and original dataframe\n",
    "print(\"\\n\\n\\n\\nHere is the onehot version of data below: \")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number with missing values larger than 0.5 to be dropped is:  1507\n",
      "\n",
      "The total number of columns is:  2430\n",
      "\n",
      "After trimming, now the number of columns above the criteria is:  0\n",
      "\n",
      "The total column now is:  923\n"
     ]
    }
   ],
   "source": [
    "#------------------------------drop the missing value features---------------------\n",
    "# declare a missing ratio criteria for trimming the data\n",
    "trim_crt = 0.20\n",
    "# drop the column with a lot of missing values\n",
    "drop_col_bol = df.isna().mean() > trim_crt\n",
    "# number of columns with missing value larger than the criterion\n",
    "print('The total number with missing values larger than 0.5 to be dropped is: ', sum(drop_col_bol))\n",
    "# total numbers of columns\n",
    "print('\\nThe total number of columns is: ', df.shape[1])\n",
    "# delete the columns with missing values larger than the criterion\n",
    "df = df.loc[:, df.columns[~drop_col_bol]]\n",
    "# check if we delete all\n",
    "print('\\nAfter trimming, now the number of columns above the criteria is: ', sum(df.isna().mean() > trim_crt))\n",
    "# print the total column number\n",
    "print('\\nThe total column now is: ', df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>RIDSTATR</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>RIDAGEYR</th>\n",
       "      <th>RIDRETH1</th>\n",
       "      <th>RIDRETH3</th>\n",
       "      <th>RIDEXMON</th>\n",
       "      <th>DMDBORN4</th>\n",
       "      <th>DMDCITZN</th>\n",
       "      <th>...</th>\n",
       "      <th>SMD100BR__USA GOLD</th>\n",
       "      <th>SMD100BR__VIRGINIA SLIMS</th>\n",
       "      <th>SMD100BR__VIRGINIA SLIMS GOLD</th>\n",
       "      <th>SMD100BR__VIRGINIA SLIMS SUPERSLIMS</th>\n",
       "      <th>SMD100BR__VIRGINIA SLIMS SUPERSLIMS GOLD</th>\n",
       "      <th>SMD100BR__WAVE</th>\n",
       "      <th>SMD100BR__WILD HORSE RED</th>\n",
       "      <th>SMD100BR__WINSTON</th>\n",
       "      <th>SMD100BR__WINSTON GOLD</th>\n",
       "      <th>SMD100BR__WINSTON RED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76195</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76958</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80248</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80213</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76753</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 923 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SEQN  SDDSRVYR  RIDSTATR  RIAGENDR  RIDAGEYR  RIDRETH1  RIDRETH3  \\\n",
       "0  76195         8         2         1        18         5         7   \n",
       "1  76958         8         2         2        57         2         2   \n",
       "2  80248         8         2         2        29         2         2   \n",
       "3  80213         8         2         2         0         1         1   \n",
       "4  76753         8         2         1        61         3         3   \n",
       "\n",
       "   RIDEXMON  DMDBORN4  DMDCITZN  ...  SMD100BR__USA GOLD  \\\n",
       "0       1.0         1       1.0  ...                   0   \n",
       "1       1.0         1       1.0  ...                   0   \n",
       "2       2.0         1       1.0  ...                   0   \n",
       "3       2.0         1       1.0  ...                   0   \n",
       "4       2.0         1       1.0  ...                   0   \n",
       "\n",
       "   SMD100BR__VIRGINIA SLIMS  SMD100BR__VIRGINIA SLIMS GOLD  \\\n",
       "0                         0                              0   \n",
       "1                         0                              0   \n",
       "2                         0                              0   \n",
       "3                         0                              0   \n",
       "4                         0                              0   \n",
       "\n",
       "   SMD100BR__VIRGINIA SLIMS SUPERSLIMS  \\\n",
       "0                                    0   \n",
       "1                                    0   \n",
       "2                                    0   \n",
       "3                                    0   \n",
       "4                                    0   \n",
       "\n",
       "   SMD100BR__VIRGINIA SLIMS SUPERSLIMS GOLD  SMD100BR__WAVE  \\\n",
       "0                                         0               0   \n",
       "1                                         0               0   \n",
       "2                                         0               0   \n",
       "3                                         0               0   \n",
       "4                                         0               0   \n",
       "\n",
       "   SMD100BR__WILD HORSE RED  SMD100BR__WINSTON  SMD100BR__WINSTON GOLD  \\\n",
       "0                         0                  0                       0   \n",
       "1                         0                  0                       0   \n",
       "2                         0                  0                       0   \n",
       "3                         0                  0                       0   \n",
       "4                         0                  0                       0   \n",
       "\n",
       "   SMD100BR__WINSTON RED  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 923 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#----------------------------Replace the rest of NaN with means--------------------------\n",
    "df = df.fillna(df.mean())\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Originally the total number of instances is:  8140\n",
      "\n",
      "After eliminating the outliers, the number of instances left is:  5464\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>RIDSTATR</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>RIDAGEYR</th>\n",
       "      <th>RIDRETH1</th>\n",
       "      <th>RIDRETH3</th>\n",
       "      <th>RIDEXMON</th>\n",
       "      <th>DMDBORN4</th>\n",
       "      <th>DMDCITZN</th>\n",
       "      <th>...</th>\n",
       "      <th>SMD100BR__USA GOLD</th>\n",
       "      <th>SMD100BR__VIRGINIA SLIMS</th>\n",
       "      <th>SMD100BR__VIRGINIA SLIMS GOLD</th>\n",
       "      <th>SMD100BR__VIRGINIA SLIMS SUPERSLIMS</th>\n",
       "      <th>SMD100BR__VIRGINIA SLIMS SUPERSLIMS GOLD</th>\n",
       "      <th>SMD100BR__WAVE</th>\n",
       "      <th>SMD100BR__WILD HORSE RED</th>\n",
       "      <th>SMD100BR__WINSTON</th>\n",
       "      <th>SMD100BR__WINSTON GOLD</th>\n",
       "      <th>SMD100BR__WINSTON RED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76195</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76958</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80248</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80213</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80344</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 923 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SEQN  SDDSRVYR  RIDSTATR  RIAGENDR  RIDAGEYR  RIDRETH1  RIDRETH3  \\\n",
       "0  76195         8         2         1        18         5         7   \n",
       "1  76958         8         2         2        57         2         2   \n",
       "2  80248         8         2         2        29         2         2   \n",
       "3  80213         8         2         2         0         1         1   \n",
       "4  80344         8         2         2        21         3         3   \n",
       "\n",
       "   RIDEXMON  DMDBORN4  DMDCITZN  ...  SMD100BR__USA GOLD  \\\n",
       "0       1.0         1       1.0  ...                   0   \n",
       "1       1.0         1       1.0  ...                   0   \n",
       "2       2.0         1       1.0  ...                   0   \n",
       "3       2.0         1       1.0  ...                   0   \n",
       "4       1.0         1       1.0  ...                   0   \n",
       "\n",
       "   SMD100BR__VIRGINIA SLIMS  SMD100BR__VIRGINIA SLIMS GOLD  \\\n",
       "0                         0                              0   \n",
       "1                         0                              0   \n",
       "2                         0                              0   \n",
       "3                         0                              0   \n",
       "4                         0                              0   \n",
       "\n",
       "   SMD100BR__VIRGINIA SLIMS SUPERSLIMS  \\\n",
       "0                                    0   \n",
       "1                                    0   \n",
       "2                                    0   \n",
       "3                                    0   \n",
       "4                                    0   \n",
       "\n",
       "   SMD100BR__VIRGINIA SLIMS SUPERSLIMS GOLD  SMD100BR__WAVE  \\\n",
       "0                                         0               0   \n",
       "1                                         0               0   \n",
       "2                                         0               0   \n",
       "3                                         0               0   \n",
       "4                                         0               0   \n",
       "\n",
       "   SMD100BR__WILD HORSE RED  SMD100BR__WINSTON  SMD100BR__WINSTON GOLD  \\\n",
       "0                         0                  0                       0   \n",
       "1                         0                  0                       0   \n",
       "2                         0                  0                       0   \n",
       "3                         0                  0                       0   \n",
       "4                         0                  0                       0   \n",
       "\n",
       "   SMD100BR__WINSTON RED  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "\n",
       "[5 rows x 923 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#---------------------------------Outlier Elimination-----------------------------------\n",
    "# drop the outliers with values outside of m +/- 3*s.t.d \n",
    "outlier_bol_upper = (df <= (df.mean() + 10 * df.std())).astype('int')\n",
    "outlier_bol_lower = (df >= (df.mean() - 10 * df.std())).astype('int')\n",
    "outlier_bol = np.logical_and(outlier_bol_upper, outlier_bol_lower)\n",
    "# max((~outlier_bol).sum()) # check what is the maximum number of outliers in any of these columns\n",
    "# sum((~outlier_bol).sum() == 8140) # check if there are columns with all being outliers (wrong)\n",
    "print('Originally the total number of instances is: ', outlier_bol.shape[0])\n",
    "outlier_bol = outlier_bol.all(axis = 1)\n",
    "print('\\nAfter eliminating the outliers, the number of instances left is: ', sum(outlier_bol))\n",
    "# trim the dataframe\n",
    "df = df.loc[df.index[outlier_bol],:].reset_index(drop = True)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the feature and the result\n",
    "X = df.drop(['DIABETIC'], axis = 1)\n",
    "y = df['DIABETIC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F_HqomJOap0j"
   },
   "source": [
    "## **Modeling**\n",
    "\n",
    "In this section, you are tasked with building a Decision Tree classifier to predict whether or not a patient has diabetes. The overall goal of this exercise is to investigate the dataset and develop features that would improve your model performance.\n",
    "\n",
    "To help with this process, we have provided the structure for two helper functions. These functions will help in tuning your model as well as validating your model's performance.\n",
    "\n",
    "Complete these two functions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rsr6KV5wKfJB"
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# dftest2 = pd.DataFrame({'A':[1,2,3,4,5,5,5,6,7],'B':[0,1,0,1,0,1,1,0,1]})\n",
    "# skf = StratifiedKFold(n_splits=4, random_state = None)\n",
    "# dftest2_A = dftest2.drop(['B'], axis = 1)\n",
    "# dftest2_B = dftest2['B']\n",
    "# display(dftest2_A)\n",
    "# for train_index, test_index in skf.split(dftest2_A, dftest2_B):\n",
    "#     print(\"Train: \", train_index, \"Test: \", test_index)\n",
    "\n",
    "def cross_validated_accuracy(DecisionTreeClassifier, X, y, num_trials, num_folds, random_seed):\n",
    "    random.seed(random_seed)\n",
    "    \"\"\"\n",
    "   Args:\n",
    "        DecisionTreeClassifier: An Sklearn DecisionTreeClassifier (e.g., created by \"tree.DecisionTreeClassifier(criterion='entropy')\")\n",
    "        X: Input features\n",
    "        y: Labels\n",
    "        num_trials: Number of trials to run of cross validation\n",
    "        num_folds: Number of folds (the \"k\" in \"k-folds\")\n",
    "        random_seed: Seed for uniform execution (Do not change this) \n",
    "\n",
    "    Returns:\n",
    "        cvScore: The mean accuracy of the cross-validation experiment\n",
    "\n",
    "    Notes:\n",
    "        1. You may NOT use the cross-validation functions provided by Sklearn\n",
    "    \"\"\"\n",
    "    ## TODO ##\n",
    "    \"\"\" Method 1 using RepeatedStratifiedKFold (prohibited )\n",
    "    from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "    rskf = RepeatedStratifiedKFold(n_splits = num_folds, n_repeats = num_trials,\n",
    "                                   random_state = random_seed)\n",
    "    scores = np.zeros(num_trials * num_folds) # intialize a score array with 0 entries\n",
    "    # loop through all the trials(repetitions) and all the folds. \n",
    "    # Two for loops nested together in fact\n",
    "    # the dataset gets shuffled before each trial/repetition\n",
    "    count = 0\n",
    "    for train_index, test_index in rskf.split(X, y):\n",
    "        # get the x_train and x_test\n",
    "        X_train, X_test = X.loc[train_index, :], X.loc[test_index, :]\n",
    "        # get the y_train and y_test\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "        # Model the tree\n",
    "        clf = DecisionTreeClassifier.fit(X_train, y_train) \n",
    "        # prediction\n",
    "        y_predict = clf.predict(X_test)\n",
    "        # calculate the accuracy\n",
    "        scores[count] = (y_test == y_predict).mean()\n",
    "        count += 1 # update the counter\n",
    "    \n",
    "    cvScore = scores.mean() # get the mean accuracy\n",
    "    # print('The score array is: ', scores)\n",
    "    print('\\nThe CV estimate of test error (Unpruned): %0.2f (+/- %0.2f)' % (1-cvScore, cvScore.std()*2))\n",
    "    print('\\nThe mean accuracy of the cross-validation is %0.2f: ' % cvScore)\n",
    "    \"\"\"\n",
    "    #================Method 2=====================\n",
    "    # intialize a score array with 0 entries\n",
    "    scores = []\n",
    "    cvScore = 0; # initialize\n",
    "    for i in range(num_trials):\n",
    "        # concatenate two dataframes together before shuffling\n",
    "        combined_xy = pd.concat([X, y], axis = 1)\n",
    "        # shuffle with fixed random state\n",
    "        combined_xy = combined_xy.sample(frac = 1, replace = False, random_state = random_seed)\n",
    "        # split X and y again after shuffling\n",
    "        X = df.drop(['DIABETIC'], axis = 1)\n",
    "        y = df['DIABETIC']\n",
    "        # create a index array for accessing \"moving\" test data\n",
    "        mov_test_indices = [0] # first index must be 0\n",
    "        # since the number of samples may not be divisble by number of folds\n",
    "        # so the first sample should be the quotient plus the remainder\n",
    "        # follwing the equation: (X mod n) + (x // n). should also -1 due to index\n",
    "        remainder = (combined_xy.shape[0] % num_folds)\n",
    "        quotient = (combined_xy.shape[0] // num_folds)\n",
    "        mov_test_indices.append(remainder + quotient - 1)\n",
    "        # the rest (n-1) folds have samples equaling to quotient computed above\n",
    "        mov_test_indices = mov_test_indices + [quotient] * (num_folds - 1)\n",
    "        # cumsum all the indices to get rid of the summing later on\n",
    "        mov_test_indices = list(np.cumsum(mov_test_indices))\n",
    "        for j in range(num_folds):\n",
    "            test_upper_bound = mov_test_indices[j]\n",
    "            test_lower_bound = mov_test_indices[j + 1]\n",
    "            X_test = X.iloc[test_upper_bound: test_lower_bound, :]\n",
    "            y_test = y.iloc[test_upper_bound: test_lower_bound]\n",
    "            # concatenate the rest of X and y data as the train data\n",
    "            X_train = pd.concat([X.iloc[0: test_upper_bound, :], X.iloc[test_lower_bound:, :]],axis = 0)\n",
    "            y_train = pd.concat([y.iloc[0: test_upper_bound], y.iloc[test_lower_bound:]],axis = 0)\n",
    "            # Model the tree\n",
    "            clf = DecisionTreeClassifier.fit(X_train, y_train)\n",
    "            y_predict = clf.predict(X_test)\n",
    "            # calculate the accuracy\n",
    "            scores.append((y_test == y_predict).mean())\n",
    "            \n",
    "    # get the mean accuracy \n",
    "    cvScore = np.asarray(scores).mean() \n",
    "    print('\\nThe CV estimate of test error (Unpruned): %0.2f (+/- %0.2f)' % (1-cvScore, cvScore.std()*2))\n",
    "    print('\\nThe mean accuracy of the cross-validation is %0.2f: ' % cvScore)\n",
    "    \n",
    "    return cvScore\n",
    "\n",
    "# from sklearn import tree\n",
    "# clf = tree.DecisionTreeClassifier(criterion = 'entropy')\n",
    "# num_trials, num_folds, random_seed = 10, 10, 10\n",
    "# cvScore = cross_validated_accuracy(clf, X, y, num_trials, num_folds, random_seed)\n",
    "# print('\\nThe CV score is: ' , cvScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XNISvwuvKvjP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.02 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.98: \n",
      "================== 1 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 2 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 3 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 4 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 5 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 6 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 7 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 8 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 9 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 10 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 11 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 12 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 13 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 14 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 15 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 16 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 17 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 18 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 19 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 20 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 21 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 22 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 23 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 24 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 25 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 26 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 27 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 28 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.01 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.99: \n",
      "================== 29 =======================\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "[0, 549, 1095, 1641, 2187, 2733, 3279, 3825, 4371, 4917, 5463]\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.06 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.94: \n",
      "The accuracy list is:  [0.977647971336496, 0.9890159931143541, 0.9890159931143541, 0.9890159931143541, 0.9890159931143541, 0.9890159931143541, 0.9890159931143541, 0.9890159931143541, 0.9890159931143541, 0.9890159931143541, 0.9890159931143541, 0.9890159931143541, 0.9890159931143541, 0.9890159931143541, 0.9890159931143541, 0.9890159931143541, 0.9890159931143541, 0.9890159931143541, 0.9890159931143541, 0.9890159931143541, 0.9890159931143541, 0.9890159931143541, 0.9890159931143541, 0.9890159931143541, 0.9890159931143541, 0.9890159931143541, 0.9890159931143541, 0.9890159931143541, 0.9890159931143541, 0.9379561240216978]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def automatic_dt_pruning(DecisionTreeClassifier, X, y, num_trials, num_folds, random_seed):\n",
    "    random.seed(random_seed)\n",
    "    \"\"\"\n",
    "    Returns the pruning parameter (i.e., ccp_alpha) with the highest cross-validated accuracy\n",
    "      Args:\n",
    "            DecisionTreeClassifier  : An Sklearn DecisionTreeClassifier (e.g., created by \"tree.DecisionTreeClassifier(criterion='entropy')\")      \n",
    "            X (Pandas.DataFrame)    : Input Features\n",
    "            y (Pandas.Series)       : Labels\n",
    "            num_trials              : Number of trials to run of cross validation\n",
    "            num_folds               : Number of folds for cross validation (The \"k\" in \"k-folds\") \n",
    "            random_seed             : Seed for uniform execution (Do not change this)\n",
    "\n",
    "        Returns:\n",
    "            ccp_alpha : Tuned pruning paramter with highest cross-validated accuracy\n",
    "\n",
    "        Notes:\n",
    "            1. Don't change any other Decision Tree Classifier parameters other than ccp_alpha\n",
    "            2. Use the cross_validated_accuracy function you implemented to find the cross-validated accuracy\n",
    "    \"\"\"\n",
    "  ## TODO ##\n",
    "    # greater value the ccp_alpha is, it increases the nodes being pruned\n",
    "    # so let's start the ccp_alpha at 0.\n",
    "    step_size = 0.01\n",
    "    ccp_value = 0\n",
    "    accuracy_list = []\n",
    "    ccp_list = []\n",
    "    clf = DecisionTreeClassifier\n",
    "    tracker = 0;\n",
    "    stop_threshold = 60\n",
    "    while True:\n",
    "        clf.set_params(ccp_alpha = ccp_value)\n",
    "        accuracy_list.append(cross_validated_accuracy(clf, X, y, num_trials, num_folds, random_seed))\n",
    "        ccp_value += step_size\n",
    "        ccp_list.append(ccp_value)\n",
    "        if accuracy_list[tracker] < accuracy_list[tracker - 1]:\n",
    "            break\n",
    "        if tracker == stop_threshold: # if it takes too long \n",
    "            break\n",
    "        tracker += 1\n",
    "        print('==================', tracker, '=======================')\n",
    "        \n",
    "    print('The accuracy list is: ', accuracy_list)\n",
    "    # get the last/largest ccp_value as the best ccp_alpha \n",
    "    # since we want to pruned the tree as much as we can\n",
    "    ccp_alpha = ccp_list[-1]\n",
    "    return ccp_alpha\n",
    "\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(criterion = 'entropy')\n",
    "automatic_dt_pruning(clf, X, y, 10,10,10)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 11, 21, 31, 41, 51, 61, 71, 81, 91]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = [1]\n",
    "b = a + [10]*9\n",
    "c = list(np.cumsum(b))\n",
    "print(c)\n",
    "c[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-LfgMo78b6SQ"
   },
   "source": [
    "## **Tuning and Testing**\n",
    "\n",
    "With the helper functions and your processed dataset, build a Decision Tree classifier to classify Diabetic patients and tune it to maximize model performance.\n",
    "\n",
    "Once you are done with your modeling process, test your model on the test dataset and output your predictions in a file titled \"cis519_hw1_predictions.csv\", with one row per prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSVrMo_RcYti"
   },
   "outputs": [],
   "source": [
    "## TODO ##"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW1_Skeleton.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
