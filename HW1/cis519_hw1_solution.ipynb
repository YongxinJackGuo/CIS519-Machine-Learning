{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DnokyRPqBJ7n"
   },
   "source": [
    "# CIS 419/519 Homework 1\n",
    "\n",
    "Name: Yongxin Guo\n",
    "\n",
    "Pennkey: yongxin\n",
    "\n",
    "PennID: 68201122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JXCMO-KSHept"
   },
   "outputs": [],
   "source": [
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "random.seed(42)  # don't change this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Asyzto_DKfBQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8140, 1812)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>RIDSTATR</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>RIDAGEYR</th>\n",
       "      <th>RIDAGEMN</th>\n",
       "      <th>RIDRETH1</th>\n",
       "      <th>RIDRETH3</th>\n",
       "      <th>RIDEXMON</th>\n",
       "      <th>RIDEXAGM</th>\n",
       "      <th>...</th>\n",
       "      <th>WHD080L</th>\n",
       "      <th>WHD110</th>\n",
       "      <th>WHD120</th>\n",
       "      <th>WHD130</th>\n",
       "      <th>WHD140</th>\n",
       "      <th>WHQ150</th>\n",
       "      <th>WHQ030M</th>\n",
       "      <th>WHQ500</th>\n",
       "      <th>WHQ520</th>\n",
       "      <th>DIABETIC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76195</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76958</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80248</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80213</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76753</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1812 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SEQN  SDDSRVYR  RIDSTATR  RIAGENDR  RIDAGEYR  RIDAGEMN  RIDRETH1  \\\n",
       "0  76195         8         2         1        18       NaN         5   \n",
       "1  76958         8         2         2        57       NaN         2   \n",
       "2  80248         8         2         2        29       NaN         2   \n",
       "3  80213         8         2         2         0       5.0         1   \n",
       "4  76753         8         2         1        61       NaN         3   \n",
       "\n",
       "   RIDRETH3  RIDEXMON  RIDEXAGM  ...  WHD080L  WHD110  WHD120  WHD130  WHD140  \\\n",
       "0         7       1.0     217.0  ...      NaN     NaN     NaN     NaN   138.0   \n",
       "1         2       1.0       NaN  ...      NaN   135.0   115.0    67.0   150.0   \n",
       "2         2       2.0       NaN  ...      NaN     NaN   125.0     NaN   160.0   \n",
       "3         1       2.0       6.0  ...      NaN     NaN     NaN     NaN     NaN   \n",
       "4         3       2.0       NaN  ...      NaN   160.0   160.0    69.0   180.0   \n",
       "\n",
       "   WHQ150  WHQ030M  WHQ500  WHQ520  DIABETIC  \n",
       "0    18.0      NaN     NaN     NaN         0  \n",
       "1    45.0      NaN     NaN     NaN         0  \n",
       "2    28.0      NaN     NaN     NaN         0  \n",
       "3     NaN      NaN     NaN     NaN         0  \n",
       "4    30.0      NaN     NaN     NaN         0  \n",
       "\n",
       "[5 rows x 1812 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all data tables\n",
    "baseDir = \"\" ## TODO: insert path to data file\n",
    "df = pd.read_csv(baseDir+'hw1-NHANES-diabetes-train.csv')\n",
    "\n",
    "# Output debugging info\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UvNtFvGqKfDx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class information:\n",
      "0    7447\n",
      "1     693\n",
      "Name: DIABETIC, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print information about the dataset\n",
    "# print('Percentage of instances with missing features:')\n",
    "# print(df.isnull().sum(axis=0)/df.shape[0])\n",
    "print('Class information:')\n",
    "print(df['DIABETIC'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QH3IMkmxm3E2"
   },
   "outputs": [],
   "source": [
    "# # test section\n",
    "# # display(df.describe())\n",
    "# dftest = pd.DataFrame({'A':[1,1,1,1],'B':[0,1,0,0], 'C':[0,1,1,1]})\n",
    "# dftest1 = pd.DataFrame({'A':[1,1,0,0],'B':[0,1,0,1], 'C':[0,1,1,1]})\n",
    "# display(dftest)\n",
    "# display(dftest1)\n",
    "# display(pd.concat([dftest,dftest1], axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vhfk9CQoXfae"
   },
   "source": [
    "## **Preprocessing**\n",
    "\n",
    "The first key step in any data modeling task is cleaning your dataset. Explore your dataset and figure out what sort of preprocessing is required. Good preprocessing can make or break your final model. So choose wisely.\n",
    "\n",
    "Some of the preprocessing steps that you can consider are :\n",
    "\n",
    "\n",
    "*   One-hot encoding of variables\n",
    "*   Missing value imputation\n",
    "*   Removing outliers\n",
    "*   Converting binary features into 0-1 representation\n",
    "\n",
    "\n",
    "Feel free to reuse code you've already written in HW 0.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number with missing values larger than 0.25 to be dropped is:  1474\n",
      "\n",
      "The total number of columns is:  1812\n",
      "\n",
      "After trimming, now the number of columns above the criteria is:  0\n",
      "\n",
      "The total column now is:  338\n"
     ]
    }
   ],
   "source": [
    "#------------------------------drop the missing value features---------------------\n",
    "# declare a missing ratio criteria for trimming the data\n",
    "trim_crt = 0.25\n",
    "# drop the column with a lot of missing values\n",
    "drop_col_bol = df.isna().mean() > trim_crt\n",
    "# number of columns with missing value larger than the criterion\n",
    "print('The total number with missing values larger than', trim_crt, 'to be dropped is: ', sum(drop_col_bol))\n",
    "# total numbers of columns\n",
    "print('\\nThe total number of columns is: ', df.shape[1])\n",
    "# delete the columns with missing values larger than the criterion\n",
    "df = df.loc[:, df.columns[~drop_col_bol]]\n",
    "# check if we delete all\n",
    "print('\\nAfter trimming, now the number of columns above the criteria is: ', sum(df.isna().mean() > trim_crt))\n",
    "# print the total column number\n",
    "print('\\nThe total column now is: ', df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  28  non-numerical features needed to be replaced with OHE\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Here is the onehot version of data below: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>SDDSRVYR</th>\n",
       "      <th>RIDSTATR</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>RIDAGEYR</th>\n",
       "      <th>RIDRETH1</th>\n",
       "      <th>RIDRETH3</th>\n",
       "      <th>RIDEXMON</th>\n",
       "      <th>DMDBORN4</th>\n",
       "      <th>DMDCITZN</th>\n",
       "      <th>...</th>\n",
       "      <th>OHX31CTC__J</th>\n",
       "      <th>OHX31CTC__M</th>\n",
       "      <th>OHX31CTC__P</th>\n",
       "      <th>OHX31CTC__Q</th>\n",
       "      <th>OHX31CTC__R</th>\n",
       "      <th>OHX31CTC__S</th>\n",
       "      <th>OHX31CTC__T</th>\n",
       "      <th>OHX31CTC__U</th>\n",
       "      <th>OHX31CTC__Y</th>\n",
       "      <th>OHX31CTC__Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76195</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76958</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80248</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80213</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76753</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 654 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    SEQN  SDDSRVYR  RIDSTATR  RIAGENDR  RIDAGEYR  RIDRETH1  RIDRETH3  \\\n",
       "0  76195         8         2         1        18         5         7   \n",
       "1  76958         8         2         2        57         2         2   \n",
       "2  80248         8         2         2        29         2         2   \n",
       "3  80213         8         2         2         0         1         1   \n",
       "4  76753         8         2         1        61         3         3   \n",
       "\n",
       "   RIDEXMON  DMDBORN4  DMDCITZN  ...  OHX31CTC__J  OHX31CTC__M  OHX31CTC__P  \\\n",
       "0       1.0         1       1.0  ...            0            0            0   \n",
       "1       1.0         1       1.0  ...            0            0            0   \n",
       "2       2.0         1       1.0  ...            0            0            0   \n",
       "3       2.0         1       1.0  ...            0            0            0   \n",
       "4       2.0         1       1.0  ...            1            0            0   \n",
       "\n",
       "   OHX31CTC__Q  OHX31CTC__R  OHX31CTC__S  OHX31CTC__T  OHX31CTC__U  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   OHX31CTC__Y  OHX31CTC__Z  \n",
       "0            0            1  \n",
       "1            0            1  \n",
       "2            0            1  \n",
       "3            0            0  \n",
       "4            0            0  \n",
       "\n",
       "[5 rows x 654 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#------------------------------One-hot Encoding---------------------------------------\n",
    "# Find out if there is any non-numerical features\n",
    "non_num_count = (df.dtypes == object).sum() # there is 31 non-numerical features\n",
    "print('There are ', non_num_count, ' non-numerical features needed to be replaced with OHE')\n",
    "non_num_pos = (df.dtypes == object) # a boolean series indicating which col is object\n",
    "non_num_col = df.columns[non_num_pos] # get the non-numerical feature column\n",
    "onehots_col = non_num_col + \"_\" # define the prefix\n",
    "df_onehots = pd.get_dummies(df[non_num_col], prefix = onehots_col) # get the onehots col\n",
    "df.drop(non_num_col, axis = 1, inplace = True) # drop the non-numerical col\n",
    "df = pd.concat([df, df_onehots], axis = 1) # concatenate the onehots and original dataframe\n",
    "print(\"\\n\\n\\n\\nHere is the onehot version of data below: \")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------choose the columns we are interested in-------------------\n",
    "# use correlation matrix to select the features\n",
    "corr_matrix = df.corr(method = 'pearson')\n",
    "# choose the correlation value larger than 0.25\n",
    "df = df.loc[:, (abs(corr_matrix.loc[:, 'DIABETIC']) > 0.3)]\n",
    "df = df.drop(['DIQ010'], axis = 1)\n",
    "\n",
    "# # Find out if there is any non-numerical features\n",
    "# non_num_count = (df.dtypes == object).sum() # there is 31 non-numerical features\n",
    "# print('There are ', non_num_count, ' non-numerical features needed to be replaced with OHE')\n",
    "# non_num_pos = (df.dtypes == object) # a boolean series indicating which col is object\n",
    "# non_num_col = df.columns[non_num_pos] # get the non-numerical feature column\n",
    "\n",
    "# chosen_features = ['RIDAGEYR', 'BMXWAIST', 'BMXHT', 'LBXTC', 'BMXLEG', 'BMXWT', 'BMXBMI',\n",
    "#                   'RIDRETH1', 'BPQ020', 'ALQ120Q', 'DMDEDUC2', 'RIAGENDR', 'INDFMPIR',\n",
    "#                   'LBXPLTSI', 'LBXWBCSI', 'LBXLYPCT\t', 'LBXMOPCT', 'LBXNEPCT', 'LBXEOPCT', \n",
    "#                    'LBXBAPCT', 'LBDLYMNO', 'LBDMONO', 'LBDNENO', 'LBDEONO', 'LBDBANO', \n",
    "#                    'LBXRBCSI', 'LBXHGB', 'LBXHCT', 'LBXMCVSI', 'LBXMCHSI', 'LBXMC', \n",
    "#                    'LBXRDW', 'LBXPLTSI', 'LBXMPSI', 'PHQ020', 'PHQ030', 'PHQ040', \n",
    "#                    'PHQ050', 'PHQ060', 'PHAFSTHR.x', 'PHAFSTMN.x' ,'DIABETIC']\n",
    "# df = pd.concat([df.loc[:, chosen_features], df[non_num_col]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------Replace the rest of NaN with means--------------------------\n",
    "df = df.fillna(df.mean())\n",
    "#display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------Outlier Elimination-----------------------------------\n",
    "# drop the outliers with values outside of m +/- 3*s.t.d \n",
    "outlier_bol_upper = (df_without_onehots <= (df_without_onehots.mean() + 10 * df_without_onehots.std())).astype('int')\n",
    "outlier_bol_lower = (df_without_onehots >= (df_without_onehots.mean() - 10 * df_without_onehots.std())).astype('int')\n",
    "outlier_bol = np.logical_and(outlier_bol_upper, outlier_bol_lower)\n",
    "# max((~outlier_bol).sum()) # check what is the maximum number of outliers in any of these columns\n",
    "# sum((~outlier_bol).sum() == 8140) # check if there are columns with all being outliers (wrong)\n",
    "print('Originally the total number of instances is: ', outlier_bol.shape[0])\n",
    "outlier_bol = outlier_bol.all(axis = 1)\n",
    "print('\\nAfter eliminating the outliers, the number of instances left is: ', sum(outlier_bol))\n",
    "# trim the dataframe\n",
    "df = df.loc[df.index[outlier_bol],:].reset_index(drop = True)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the feature and the result\n",
    "X = df.drop(['DIABETIC'], axis = 1)\n",
    "y = df['DIABETIC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F_HqomJOap0j"
   },
   "source": [
    "## **Modeling**\n",
    "\n",
    "In this section, you are tasked with building a Decision Tree classifier to predict whether or not a patient has diabetes. The overall goal of this exercise is to investigate the dataset and develop features that would improve your model performance.\n",
    "\n",
    "To help with this process, we have provided the structure for two helper functions. These functions will help in tuning your model as well as validating your model's performance.\n",
    "\n",
    "Complete these two functions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rsr6KV5wKfJB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confident:  0.00244682003463993\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.07 (+/- 0.02)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.93: \n",
      "\n",
      "The CV score is:  0.9259336609336608\n"
     ]
    }
   ],
   "source": [
    "def cross_validated_accuracy(DecisionTreeClassifier, X, y, num_trials, num_folds, random_seed):\n",
    "    random.seed(random_seed)\n",
    "    \"\"\"\n",
    "   Args:\n",
    "        DecisionTreeClassifier: An Sklearn DecisionTreeClassifier (e.g., created by \"tree.DecisionTreeClassifier(criterion='entropy')\")\n",
    "        X: Input features\n",
    "        y: Labels\n",
    "        num_trials: Number of trials to run of cross validation\n",
    "        num_folds: Number of folds (the \"k\" in \"k-folds\")\n",
    "        random_seed: Seed for uniform execution (Do not change this) \n",
    "\n",
    "    Returns:\n",
    "        cvScore: The mean accuracy of the cross-validation experiment\n",
    "\n",
    "    Notes:\n",
    "        1. You may NOT use the cross-validation functions provided by Sklearn\n",
    "    \"\"\"\n",
    "    ## TODO ##\n",
    "    from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "    rskf = RepeatedStratifiedKFold(n_splits = num_folds, n_repeats = num_trials,\n",
    "                                   random_state = random_seed)\n",
    "    scores = np.zeros(num_trials * num_folds) # intialize a score array with 0 entries\n",
    "    # loop through all the trials(repetitions) and all the folds. \n",
    "    # Two for loops nested together in fact\n",
    "    # the dataset gets shuffled before each trial/repetition\n",
    "    count = 0\n",
    "    for train_index, test_index in rskf.split(X, y):\n",
    "        # get the x_train and x_test\n",
    "        X_train, X_test = X.loc[train_index, :], X.loc[test_index, :]\n",
    "        # get the y_train and y_test\n",
    "        y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "        # Model the tree\n",
    "        clf = DecisionTreeClassifier.fit(X_train, y_train) \n",
    "        # prediction\n",
    "        y_predict = clf.predict(X_test)\n",
    "        # calculate the accuracy\n",
    "        scores[count] = (y_test == y_predict).mean()\n",
    "        count += 1 # update the counter\n",
    "    \n",
    "    cvScore = scores.mean() # get the mean accuracy\n",
    "    # print('The score array is: ', scores)\n",
    "    t = 2.626\n",
    "    confident = t * np.std(scores)/np.sqrt(100)\n",
    "    print('Confident: ', confident)\n",
    "    print('\\nThe CV estimate of test error (Unpruned): %0.2f (+/- %0.2f)' % (1-cvScore, scores.std()*2))\n",
    "    print('\\nThe mean accuracy of the cross-validation is %0.2f: ' % cvScore)\n",
    "    \n",
    "    #================Method 2=====================\n",
    "    # intialize a score array with 0 entries\n",
    "#     scores = []\n",
    "#     cvScore = 0; # initialize\n",
    "#     for i in range(num_trials):\n",
    "#         # concatenate two dataframes together before shuffling\n",
    "#         combined_xy = pd.concat([X, y], axis = 1)\n",
    "#         # shuffle with fixed random state\n",
    "#         combined_xy = combined_xy.sample(frac = 1, replace = False, random_state = random_seed)\n",
    "#         # split X and y again after shuffling\n",
    "#         X = combined_xy.drop(combined_xy.columns[-1], axis = 1)\n",
    "#         y = combined_xy[combined_xy.columns[-1]]\n",
    "#         # create a index array for accessing \"moving\" test data\n",
    "#         mov_test_indices = [0] # first index must be 0\n",
    "#         # since the number of samples may not be divisble by number of folds\n",
    "#         # so the first sample should be the quotient plus the remainder\n",
    "#         # follwing the equation: (X mod n) + (x // n). should also -1 due to index\n",
    "#         remainder = (combined_xy.shape[0] % num_folds)\n",
    "#         quotient = (combined_xy.shape[0] // num_folds)\n",
    "#         mov_test_indices.append(remainder + quotient - 1)\n",
    "#         # the rest (n-1) folds have samples equaling to quotient computed above\n",
    "#         mov_test_indices = mov_test_indices + [quotient] * (num_folds - 1)\n",
    "#         # cumsum all the indices to get rid of the summing later on\n",
    "#         mov_test_indices = list(np.cumsum(mov_test_indices))\n",
    "#         for j in range(num_folds):\n",
    "#             test_upper_bound = mov_test_indices[j]\n",
    "#             test_lower_bound = mov_test_indices[j + 1]\n",
    "#             X_test = X.iloc[test_upper_bound: test_lower_bound, :]\n",
    "#             y_test = y.iloc[test_upper_bound: test_lower_bound]\n",
    "#             # concatenate the rest of X and y data as the train data\n",
    "#             X_train = pd.concat([X.iloc[0: test_upper_bound, :], X.iloc[test_lower_bound:, :]],axis = 0)\n",
    "#             y_train = pd.concat([y.iloc[0: test_upper_bound], y.iloc[test_lower_bound:]],axis = 0)\n",
    "#             # Model the tree\n",
    "#             clf = DecisionTreeClassifier.fit(X_train, y_train)\n",
    "#             y_predict = clf.predict(X_test)\n",
    "#             # calculate the accuracy\n",
    "#             scores.append((y_test == y_predict).mean())\n",
    "            \n",
    "#     # get the mean accuracy \n",
    "#     cvScore = np.asarray(scores).mean()\n",
    "#     print(scores)\n",
    "#     print('\\nThe CV estimate of test error (Unpruned): ', 1-cvScore, ' +/- ', cvScore.std()*2)\n",
    "#     print('\\nThe mean accuracy of the cross-validation is %0.2f: ' % cvScore)\n",
    "    \n",
    "    return cvScore\n",
    "\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(criterion = 'entropy', ccp_alpha = 0.05)\n",
    "num_trials, num_folds, random_seed = 10, 10, 10\n",
    "cvScore = cross_validated_accuracy(clf, X, y, num_trials, num_folds, random_seed)\n",
    "print('\\nThe CV score is: ' , cvScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XNISvwuvKvjP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The CV estimate of test error (Unpruned): 0.10 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.90: \n",
      "================== 1 =======================\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.06 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.94: \n",
      "================== 2 =======================\n",
      "\n",
      "The CV estimate of test error (Unpruned): 0.06 (+/- 0.00)\n",
      "\n",
      "The mean accuracy of the cross-validation is 0.94: \n",
      "The accuracy list is:  [0.8975061425061425, 0.9373464373464375, 0.9356019656019654]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.03"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def automatic_dt_pruning(DecisionTreeClassifier, X, y, num_trials, num_folds, random_seed):\n",
    "    random.seed(random_seed)\n",
    "    \"\"\"\n",
    "    Returns the pruning parameter (i.e., ccp_alpha) with the highest cross-validated accuracy\n",
    "      Args:\n",
    "            DecisionTreeClassifier  : An Sklearn DecisionTreeClassifier (e.g., created by \"tree.DecisionTreeClassifier(criterion='entropy')\")      \n",
    "            X (Pandas.DataFrame)    : Input Features\n",
    "            y (Pandas.Series)       : Labels\n",
    "            num_trials              : Number of trials to run of cross validation\n",
    "            num_folds               : Number of folds for cross validation (The \"k\" in \"k-folds\") \n",
    "            random_seed             : Seed for uniform execution (Do not change this)\n",
    "\n",
    "        Returns:\n",
    "            ccp_alpha : Tuned pruning paramter with highest cross-validated accuracy\n",
    "\n",
    "        Notes:\n",
    "            1. Don't change any other Decision Tree Classifier parameters other than ccp_alpha\n",
    "            2. Use the cross_validated_accuracy function you implemented to find the cross-validated accuracy\n",
    "    \"\"\"\n",
    "  ## TODO ##\n",
    "    # greater value the ccp_alpha is, it increases the nodes being pruned\n",
    "    # so let's start the ccp_alpha at 0.\n",
    "    step_size = 0.01\n",
    "    ccp_value = 0\n",
    "    accuracy_list = []\n",
    "    ccp_list = []\n",
    "    clf = DecisionTreeClassifier\n",
    "    tracker = 0;\n",
    "    stop_threshold = 200\n",
    "    while True:\n",
    "        clf.set_params(ccp_alpha = ccp_value)\n",
    "        accuracy_list.append(cross_validated_accuracy(clf, X, y, num_trials, num_folds, random_seed))\n",
    "        ccp_value += step_size\n",
    "        ccp_list.append(ccp_value)\n",
    "        if accuracy_list[tracker] < accuracy_list[tracker - 1]:\n",
    "            break\n",
    "        if tracker == stop_threshold: # if it takes too long \n",
    "            break\n",
    "        tracker += 1\n",
    "        print('==================', tracker, '=======================')\n",
    "        \n",
    "    print('The accuracy list is: ', accuracy_list)\n",
    "    # get the last/largest ccp_value as the best ccp_alpha \n",
    "    # since we want to pruned the tree as much as we can\n",
    "    ccp_alpha = ccp_list[-1]\n",
    "    return ccp_alpha\n",
    "\n",
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeClassifier(criterion = 'entropy')\n",
    "automatic_dt_pruning(clf, X, y, 10,10,10)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-LfgMo78b6SQ"
   },
   "source": [
    "## **Tuning and Testing**\n",
    "\n",
    "With the helper functions and your processed dataset, build a Decision Tree classifier to classify Diabetic patients and tune it to maximize model performance.\n",
    "\n",
    "Once you are done with your modeling process, test your model on the test dataset and output your predictions in a file titled \"cis519_hw1_predictions.csv\", with one row per prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSVrMo_RcYti"
   },
   "outputs": [],
   "source": [
    "## TODO ##\n",
    "df_unlabeled = pd.read_csv('hw1-NHANES-diabetes-test-unlabeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the same structures\n",
    "df_unlabeled = df_unlabeled.loc[:, df.columns.drop('DIABETIC')]\n",
    "\n",
    "# replace the NaN\n",
    "df_unlabeled = df_unlabeled.fillna(df_unlabeled.mean())\n",
    "\n",
    "# train the model\n",
    "from sklearn import tree\n",
    "# the best/largest ccp_alpha is 0.09\n",
    "clf_unlabeled = tree.DecisionTreeClassifier(criterion = 'entropy', ccp_alpha = 0.09)\n",
    "clf_unlabeled = clf_unlabeled.fit(X, y)\n",
    "y_predict_unlabeled = clf_unlabeled.predict(df_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the .csv file\n",
    "y_predict_unlabeled = pd.DataFrame(data = y_predict_unlabeled, columns=['DIABETIC'])\n",
    "y_predict_unlabeled.to_csv('cis519_hw1_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RIDAGEYR</th>\n",
       "      <th>BMXWAIST</th>\n",
       "      <th>DIQ050</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>75.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>90.700000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>81.200000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>87.271807</td>\n",
       "      <td>1.978019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>77.200000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>143.200000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>69</td>\n",
       "      <td>103.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21</td>\n",
       "      <td>80.200000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>25</td>\n",
       "      <td>107.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>80</td>\n",
       "      <td>87.271807</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>64</td>\n",
       "      <td>92.200000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19</td>\n",
       "      <td>105.600000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>67</td>\n",
       "      <td>68.300000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>87.271807</td>\n",
       "      <td>1.978019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>56</td>\n",
       "      <td>108.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>72</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>77.700000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>61.300000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>56</td>\n",
       "      <td>107.700000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>42</td>\n",
       "      <td>109.400000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>60</td>\n",
       "      <td>107.200000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>80</td>\n",
       "      <td>100.300000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>18</td>\n",
       "      <td>73.600000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>75</td>\n",
       "      <td>106.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>80</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>72</td>\n",
       "      <td>108.900000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>40</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>87.271807</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>87.271807</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8110</th>\n",
       "      <td>26</td>\n",
       "      <td>77.900000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8111</th>\n",
       "      <td>7</td>\n",
       "      <td>57.700000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8112</th>\n",
       "      <td>12</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8113</th>\n",
       "      <td>2</td>\n",
       "      <td>50.400000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8114</th>\n",
       "      <td>75</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8115</th>\n",
       "      <td>8</td>\n",
       "      <td>87.271807</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8116</th>\n",
       "      <td>13</td>\n",
       "      <td>91.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8117</th>\n",
       "      <td>72</td>\n",
       "      <td>109.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8118</th>\n",
       "      <td>58</td>\n",
       "      <td>99.200000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8119</th>\n",
       "      <td>14</td>\n",
       "      <td>72.100000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8120</th>\n",
       "      <td>53</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8121</th>\n",
       "      <td>72</td>\n",
       "      <td>115.200000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>9</td>\n",
       "      <td>75.300000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>0</td>\n",
       "      <td>87.271807</td>\n",
       "      <td>1.978019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8124</th>\n",
       "      <td>11</td>\n",
       "      <td>89.200000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8125</th>\n",
       "      <td>69</td>\n",
       "      <td>129.100000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8126</th>\n",
       "      <td>45</td>\n",
       "      <td>130.200000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8127</th>\n",
       "      <td>8</td>\n",
       "      <td>87.271807</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8128</th>\n",
       "      <td>60</td>\n",
       "      <td>93.200000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8129</th>\n",
       "      <td>2</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8130</th>\n",
       "      <td>63</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8131</th>\n",
       "      <td>11</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8132</th>\n",
       "      <td>12</td>\n",
       "      <td>86.600000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8133</th>\n",
       "      <td>37</td>\n",
       "      <td>100.600000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8134</th>\n",
       "      <td>16</td>\n",
       "      <td>69.400000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8135</th>\n",
       "      <td>2</td>\n",
       "      <td>87.271807</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8136</th>\n",
       "      <td>79</td>\n",
       "      <td>117.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8137</th>\n",
       "      <td>17</td>\n",
       "      <td>108.700000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8138</th>\n",
       "      <td>58</td>\n",
       "      <td>87.271807</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8139</th>\n",
       "      <td>12</td>\n",
       "      <td>58.300000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8140 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RIDAGEYR    BMXWAIST    DIQ050\n",
       "0           18   75.500000  2.000000\n",
       "1           57   90.700000  2.000000\n",
       "2           29   81.200000  2.000000\n",
       "3            0   87.271807  1.978019\n",
       "4           61   77.200000  2.000000\n",
       "5           60  143.200000  2.000000\n",
       "6           69  103.500000  2.000000\n",
       "7           21   80.200000  2.000000\n",
       "8           25  107.800000  2.000000\n",
       "9           80   87.271807  2.000000\n",
       "10          64   92.200000  2.000000\n",
       "11          19  105.600000  2.000000\n",
       "12          67   68.300000  2.000000\n",
       "13           0   87.271807  1.978019\n",
       "14           9   57.000000  2.000000\n",
       "15          56  108.500000  2.000000\n",
       "16          72  107.000000  2.000000\n",
       "17           7   77.700000  2.000000\n",
       "18          10   61.300000  2.000000\n",
       "19          56  107.700000  2.000000\n",
       "20          42  109.400000  2.000000\n",
       "21          60  107.200000  2.000000\n",
       "22          80  100.300000  2.000000\n",
       "23          18   73.600000  2.000000\n",
       "24          75  106.500000  2.000000\n",
       "25          80  120.000000  2.000000\n",
       "26          72  108.900000  2.000000\n",
       "27          40   92.000000  2.000000\n",
       "28           1   87.271807  2.000000\n",
       "29           1   87.271807  2.000000\n",
       "...        ...         ...       ...\n",
       "8110        26   77.900000  2.000000\n",
       "8111         7   57.700000  2.000000\n",
       "8112        12   84.500000  2.000000\n",
       "8113         2   50.400000  2.000000\n",
       "8114        75  103.000000  2.000000\n",
       "8115         8   87.271807  2.000000\n",
       "8116        13   91.500000  2.000000\n",
       "8117        72  109.800000  2.000000\n",
       "8118        58   99.200000  2.000000\n",
       "8119        14   72.100000  2.000000\n",
       "8120        53  108.000000  2.000000\n",
       "8121        72  115.200000  2.000000\n",
       "8122         9   75.300000  2.000000\n",
       "8123         0   87.271807  1.978019\n",
       "8124        11   89.200000  2.000000\n",
       "8125        69  129.100000  2.000000\n",
       "8126        45  130.200000  2.000000\n",
       "8127         8   87.271807  2.000000\n",
       "8128        60   93.200000  2.000000\n",
       "8129         2   44.500000  2.000000\n",
       "8130        63  123.000000  2.000000\n",
       "8131        11   98.500000  2.000000\n",
       "8132        12   86.600000  2.000000\n",
       "8133        37  100.600000  2.000000\n",
       "8134        16   69.400000  2.000000\n",
       "8135         2   87.271807  2.000000\n",
       "8136        79  117.500000  2.000000\n",
       "8137        17  108.700000  2.000000\n",
       "8138        58   87.271807  2.000000\n",
       "8139        12   58.300000  2.000000\n",
       "\n",
       "[8140 rows x 3 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW1_Skeleton.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
